from __future__ import annotations

import logging
import random
import time

import cv2
import numpy as np
import os
import copy
import matplotlib.pyplot as plt
from typing import List

from bosdyn.client import Sdk
from source.robot_utils.advanced_movement import move_body_distanced, push
from source.robot_utils.base import ControlFunction, take_control_with_function
from source.robot_utils.basic_movements import carry_arm, stow_arm, move_body, gaze, carry, move_arm_distanced, move_arm
from source.robot_utils.advanced_movement import push_light_switch, turn_light_switch
from source.robot_utils.frame_transformer import FrameTransformerSingleton
from source.robot_utils.video import localize_from_images, get_camera_rgbd, set_gripper_camera_params, set_gripper, relocalize, localize_from_images_only_fiducial
from scipy.spatial.transform import Rotation
from source.utils.coordinates import Pose3D, Pose2D, pose_distanced, average_pose3Ds
from source.utils.recursive_config import Config
from source.utils.singletons import (
    GraphNavClientSingleton,
    ImageClientSingleton,
    RobotCommandClientSingleton,
    RobotSingleton,
    RobotStateClientSingleton,
    WorldObjectClientSingleton,
)
from source.utils.light_switch_detection import predict_light_switches
from source.utils.affordance_detection_light_switch import compute_affordance_VLM_GPT4, compute_advanced_affordance_VLM_GPT4
from source.bosdyn.api.image_pb2 import ImageResponse
from source.utils.object_detetion import BBox, Detection, Match
from source.robot_utils.video import frame_coordinate_from_depth_image, select_points_from_bounding_box

frame_transformer = FrameTransformerSingleton()
graph_nav_client = GraphNavClientSingleton()
image_client = ImageClientSingleton()
robot_command_client = RobotCommandClientSingleton()
robot = RobotSingleton()
robot_state_client = RobotStateClientSingleton()
world_object_client = WorldObjectClientSingleton()

from source.utils.pose_utils import calculate_light_switch_poses
from source.utils.bounding_box_refinement import refine_bounding_box
from random import uniform

from source.utils.pose_utils import (
    determine_handle_center,
    find_plane_normal_pose,
    calculate_handle_poses,
    cluster_handle_poses,
    filter_handle_poses,
    refine_handle_position,

)

AFFORDANCE_CLASSES = {0: "SINGLE PUSH",
                          1: "DOUBLE PUSH",
                          2: "ROTATING",
                          3: "something else"}

AFFORDANCE_DICT = {"button type": ["push button switch", "rotating switch", "none"],
                   "button count": ["single", "double", "none"],
                   "button position (wrt. other button!)": ["buttons stacked vertically", "buttons side-by-side", "none"],
                   "interaction inference from symbols": ["top/bot push", "left/right push", "center push", "no symbols present"]}


config = Config()
API_KEY = config["gpt_api_key"]
STAND_DISTANCE = 0.9 #1.0
GRIPPER_WIDTH = 0.03
GRIPPER_HEIGHT = 0.03
ADVANCED_AFFORDANCE = True
FORCES = [8, 0, 0, 0, 0, 0]
LOGGING_PATH = "../../logging_lightswitch_experiments/"

## TESTING PARAMETERS
TEST_NUMBER = 9
RUN =1
LEVEL = "wild"


DETECTION_DISTANCE = 0.75
X_BODY = 1.6
Y_BODY = 0.0
ANGLE_BODY = 180
SHUFFLE = True
NUM_REFINEMENT_POSES = 2
NUM_REFINEMENTS_MAX_TRIES = 5
BOUNDING_BOX_OPTIMIZATION = False

if LEVEL == "wild":
    X_CABINET = 0.15
    Y_CABINET = 0.0  # 0.9
    Z_CABINET = 0.5  # 0.42


# file_path = filename=os.path.join(LOGGING_PATH, f"switches_experiment_{TEST_NUMBER}_LEVEL_{LEVEL}_RUN_{RUN}.log")
# if os.path.exists(file_path):
#     raise FileExistsError(f"The file '{file_path}' already exists.")

logging.getLogger("understanding-spot.192.168.50.3").disabled = True
# logging.basicConfig(filename=file_path, filemode='w', format='%(name)s - %(levelname)s - %(message)s')

logging.info(f"ANGLE_BODY: {ANGLE_BODY}")
logging.info(f"X_BODY: {X_BODY}")
logging.info(f"Y_BODY: {Y_BODY}")
logging.info(f"X_CABINET: {X_CABINET}")
logging.info(f"Y_CABINET: {Y_CABINET}")
logging.info(f"Z_CABINET: {Z_CABINET}")
logging.info(f"STAND_DISTANCE: {STAND_DISTANCE}")
logging.info(f"GRIPPER_WIDTH: {GRIPPER_WIDTH}")
logging.info(f"GRIPPER_HEIGHT: {GRIPPER_HEIGHT}")
logging.info(f"ADVANCED_AFFORDANCE: {ADVANCED_AFFORDANCE}")
logging.info(f"FORCES: {FORCES}")
logging.info(f"LOGGING_PATH: {LOGGING_PATH}")
logging.info(f"TEST_NUMBER: {TEST_NUMBER}")
logging.info(f"RUN: {RUN}")
logging.info(f"LEVEL: {LEVEL}")
logging.info(f"DETECTION_DISTANCE: {DETECTION_DISTANCE}")
logging.info(f"SHUFFLE: {SHUFFLE}")
logging.info(f"NUM_REFINEMENT_POSES: {NUM_REFINEMENT_POSES}")
logging.info(f"NUM_REFINEMENTS_MAX_TRIES: {NUM_REFINEMENTS_MAX_TRIES}")

def refinement(pose: Pose3D, frame_name: str, weights_path: str, bb_optimization: bool = True):

    depth_image_response, color_response = get_camera_rgbd(
        in_frame="image", vis_block=False, cut_to_size=False
    )

    ref_boxes = predict_light_switches(color_response[0], weights_path=weights_path, vis_block=True)

    #################################
    # refined boxes
    #################################
    if bb_optimization:
        boxes = []
        for ref_box in ref_boxes:
            bb = np.array([ref_box.xmin, ref_box.ymin, ref_box.xmax, ref_box.ymax])
            bb_refined = refine_bounding_box(color_response[0], bb, vis_block=True)
            bb_refined = BBox(bb_refined[0], bb_refined[1], bb_refined[2], bb_refined[3])
            boxes.append(bb_refined)
        ref_boxes = boxes
    ###############################
    # efined boxes
    ###############################

    refined_posess = calculate_light_switch_poses(ref_boxes, depth_image_response, frame_name, frame_transformer)
    # filter refined poses
    distances = np.linalg.norm(
        np.array([refined_pose.coordinates for refined_pose in refined_posess]) - pose.coordinates, axis=1)

    # handle not finding the correct bounding box
    if distances.min() > 0.05:  # 0.05
        return None, None, None
    else:
        idx = np.argmin(distances)
        refined_pose = refined_posess[idx]
        refined_box = ref_boxes[idx]
        return refined_pose, refined_box, color_response[0]

class _Push_Light_Switch(ControlFunction):
    def __call__(
        self,
        config: Config,
        sdk: Sdk,
        *args,
        **kwargs,
    ) -> str:

        logging.info(f"ANGLE_BODY: {ANGLE_BODY}")
        logging.info(f"X_BODY: {X_BODY}")
        logging.info(f"Y_BODY: {Y_BODY}")
        logging.info(f"X_CABINET: {X_CABINET}")
        logging.info(f"Y_CABINET: {Y_CABINET}")
        logging.info(f"Z_CABINET: {Z_CABINET}")
        logging.info(f"STAND_DISTANCE: {STAND_DISTANCE}")
        logging.info(f"GRIPPER_WIDTH: {GRIPPER_WIDTH}")
        logging.info(f"GRIPPER_HEIGHT: {GRIPPER_HEIGHT}")
        logging.info(f"ADVANCED_AFFORDANCE: {ADVANCED_AFFORDANCE}")
        logging.info(f"FORCES: {FORCES}")
        logging.info(f"LOGGING_PATH: {LOGGING_PATH}")
        logging.info(f"TEST_NUMBER: {TEST_NUMBER}")
        logging.info(f"RUN: {RUN}")
        logging.info(f"LEVEL: {LEVEL}")
        logging.info(f"DETECTION_DISTANCE: {DETECTION_DISTANCE}")
        logging.info(f"SHUFFLE: {SHUFFLE}")
        logging.info(f"NUM_REFINEMENT_POSES: {NUM_REFINEMENT_POSES}")
        logging.info(f"NUM_REFINEMENTS_MAX_TRIES: {NUM_REFINEMENTS_MAX_TRIES}")

        start_time = time.time()

        set_gripper_camera_params('640x480')
        frame_name = localize_from_images_only_fiducial(config, vis_block=False)

        end_time_localization = time.time()
        logging.info(f"Localization time: {end_time_localization - start_time}")

        pose = Pose2D(np.array([X_BODY, Y_BODY]))
        pose.set_rot_from_angle(ANGLE_BODY, degrees=True)

        move_body(
            pose=pose,
            frame_name=frame_name,
        )

        cabinet_pose = Pose3D((X_CABINET, Y_CABINET, Z_CABINET))
        cabinet_pose.set_rot_from_rpy((0,0,ANGLE_BODY), degrees=True)

        carry()

        set_gripper_camera_params('1920x1080')
        time.sleep(1)
        gaze(cabinet_pose, frame_name, gripper_open=True)

        depth_image_response, color_response = get_camera_rgbd(
            in_frame="image",
            vis_block=False,
            cut_to_size=False,
        )
        set_gripper_camera_params('1280x720')
        stow_arm()

        weights_path = config.get_subpath("detection_weights")

        boxes = predict_light_switches(color_response[0], weights_path=weights_path, vis_block=True)
        logging.info(f"INITIAL LIGHT SWITCH DETECTION")
        logging.info(f"Number of detected switches: {len(boxes)}")
        end_time_detection = time.time()
        logging.info(f"Detection time: {end_time_detection - end_time_localization}")

        if SHUFFLE:
            random.shuffle(boxes)

        poses = calculate_light_switch_poses(boxes, depth_image_response, frame_name, frame_transformer)
        logging.info(f"Number of calculated poses: {len(poses)}")
        end_time_pose_calculation = time.time()
        logging.info(f"Pose calculation time: {end_time_pose_calculation - end_time_detection}")


        for idx, pose in enumerate(poses):
            pose_start_time = time.time()
            body_add_pose_refinement_right = Pose3D((-STAND_DISTANCE, -0.00, -0.00))
            body_add_pose_refinement_right.set_rot_from_rpy((0, 0, 0), degrees=True)
            p_body = pose.copy() @ body_add_pose_refinement_right.copy()
            move_body(p_body.to_dimension(2), frame_name)
            logging.info(f"Moved body to switch {idx+1} of {len(poses)}")
            end_time_move_body = time.time()
            logging.info(f"Move body time: {end_time_move_body - pose_start_time}")

            carry_arm()
            #################################
            # refine handle position
            #################################

            x_offset = -0.3 # -0.2

            camera_add_pose_refinement_right = Pose3D((x_offset, -0.05, -0.04))
            camera_add_pose_refinement_right.set_rot_from_rpy((0, 0, 0), degrees=True)
            camera_add_pose_refinement_left = Pose3D((x_offset, 0.05, -0.04))
            camera_add_pose_refinement_left.set_rot_from_rpy((0, 0, 0), degrees=True)
            camera_add_pose_refinement_bot = Pose3D((x_offset, -0.0, -0.1))
            camera_add_pose_refinement_bot.set_rot_from_rpy((0, 0, 0), degrees=True)
            camera_add_pose_refinement_top = Pose3D((x_offset, -0.0, -0.02))
            camera_add_pose_refinement_top.set_rot_from_rpy((0, 0, 0), degrees=True)


            if NUM_REFINEMENT_POSES == 4:
                ref_add_poses = [camera_add_pose_refinement_right, camera_add_pose_refinement_left,
                                 camera_add_pose_refinement_bot, camera_add_pose_refinement_top]
            elif NUM_REFINEMENT_POSES == 1:
                ref_add_poses = [camera_add_pose_refinement_right]

            elif NUM_REFINEMENT_POSES == 2:
                ref_add_poses = [camera_add_pose_refinement_right, camera_add_pose_refinement_left]

            refined_poses = []
            refined_boxes = []
            color_responses = []
            count = 0
            while count < NUM_REFINEMENTS_MAX_TRIES:
                if len(refined_poses) == 0:
                    logging.info(f"Refinement try {count+1} of {NUM_REFINEMENTS_MAX_TRIES}")
                    for idx_ref_pose, ref_pose in enumerate(ref_add_poses):
                        p = pose.copy() @ ref_pose.copy()
                        move_arm(p, frame_name, body_assist=True)
                        try:
                            refined_pose, refined_box, color_response = refinement(pose, frame_name, weights_path, BOUNDING_BOX_OPTIMIZATION)
                            if refined_pose is not None:
                                refined_poses.append(refined_pose)
                                refined_boxes.append(refined_box)
                                color_responses.append(color_response)
                        except:
                            logging.warning(f"Refinement try {count+1} failed at refinement pose {idx_ref_pose+1} of {len(ref_add_poses)}")
                            continue
                else:
                    logging.info(f"Refinement exited or finished at try {count} of {NUM_REFINEMENTS_MAX_TRIES}")
                    break
                count += 1
                time.sleep(1)

            try:
                refined_pose = average_pose3Ds(refined_poses)
            except:
                logging.warning(f"Refinement failed, no average pose could be calculated")
                continue

            logging.info(f"Refinement finished, average pose calculated")
            logging.info(f"Number of refined poses: {len(refined_poses)}")
            end_time_refinement = time.time()
            logging.info(f"Refinement time: {end_time_refinement - end_time_move_body}")
            logging.info("affordance detection starting...")
            #################################
            # affordance detection
            #################################

            refined_box = refined_boxes[-1]
            cropped_image = color_responses[-1][int(refined_box.ymin):int(refined_box.ymax), int(refined_box.xmin):int(refined_box.xmax)]
            plt.imshow(cropped_image)
            plt.show()
            affordance_dict = compute_advanced_affordance_VLM_GPT4(cropped_image, AFFORDANCE_DICT, API_KEY)
            print(affordance_dict)
            logging.info(f"Affordance detection finished")
            end_time_affordance = time.time()
            logging.info(f"Affordance time: {end_time_affordance - end_time_refinement}")

            #################################
            # interaction based on affordance
            #################################
            offsets = []
            if affordance_dict["button type"] == "rotating switch":
                turn_light_switch(refined_pose, frame_name)
            elif affordance_dict["button type"] == "push button switch":
                if affordance_dict["button count"] == "single":
                    if affordance_dict["interaction inference from symbols"] == "top/bot push":
                        offsets.append([0.0, 0.0, GRIPPER_HEIGHT/2])
                        offsets.append([0.0, 0.0, -GRIPPER_HEIGHT/2])
                    elif affordance_dict["interaction inference from symbols"] == "left/right push":
                        offsets.append([0.0, GRIPPER_WIDTH/2, 0.0])
                        offsets.append([0.0, -GRIPPER_WIDTH/2, 0.0])
                    elif affordance_dict["interaction inference from symbols"] == "no symbols present" or affordance_dict["interaction inference from symbols"] == "center push":
                        offsets.append([0.0, 0.0, 0.0])
                    else:
                        logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                        continue
                elif affordance_dict["button count"] == "double":
                    if affordance_dict["button position (wrt. other button!)"] == "buttons side-by-side":
                        if affordance_dict["interaction inference from symbols"] == "top/bot push":
                            offsets.append([0.0, GRIPPER_WIDTH/2, GRIPPER_HEIGHT/2])
                            offsets.append([0.0, GRIPPER_WIDTH/2, -GRIPPER_HEIGHT/2])
                            offsets.append([0.0, -GRIPPER_WIDTH/2, GRIPPER_HEIGHT/2])
                            offsets.append([0.0, -GRIPPER_WIDTH/2, -GRIPPER_HEIGHT/2])
                        elif affordance_dict["interaction inference from symbols"] == "left/right push":
                            logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                            continue
                        elif affordance_dict["interaction inference from symbols"] == "no symbols present" or affordance_dict["interaction inference from symbols"] == "center push":
                            offsets.append([0.0, GRIPPER_WIDTH/2, 0.0])
                            offsets.append([0.0, -GRIPPER_WIDTH/2, 0.0])
                        else:
                            logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                            continue
                    elif affordance_dict["button position (wrt. other button!)"] == "buttons stacked vertically":
                        if affordance_dict["interaction inference from symbols"] == "no symbols present" or affordance_dict["interaction inference from symbols"] == "center push":
                            offsets.append([0.0, 0.0, GRIPPER_HEIGHT/2])
                            offsets.append([0.0, 0.0, -GRIPPER_HEIGHT/2])
                        elif affordance_dict["interaction inference from symbols"] == "left/right push":
                            # todo test on robot
                            offsets.append([0.0, GRIPPER_WIDTH/2, GRIPPER_HEIGHT/2])
                            offsets.append([0.0, GRIPPER_WIDTH/2, -GRIPPER_HEIGHT/2])
                            offsets.append([0.0, -GRIPPER_WIDTH/2, GRIPPER_HEIGHT/2])
                            offsets.append([0.0, -GRIPPER_WIDTH/2, -GRIPPER_HEIGHT/2])
                        else:
                            logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                            continue
                    elif affordance_dict["button position (wrt. other button!)"] == "none":
                        logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                        continue
                    else:
                        logging.warning(f"AFFORDANCE ERROR: {affordance_dict} NOT EXPECTED")
                        continue
                for offset_coords in offsets:
                    pose_offset = copy.deepcopy(refined_pose)
                    pose_offset.coordinates += np.array(offset_coords)
                    push_light_switch(pose_offset, frame_name, z_offset=True, forces=FORCES)
                logging.info(f"Tried interaction with switch {idx+1} of {len(poses)}")
            else:
                print("THATS NOT A LIGHT SWITCH!")

            stow_arm()
            logging.info(f"Interaction with switch {idx+1} of {len(poses)} finished")
            end_time_switch = time.time()
            logging.info(f"Switch interaction time: {end_time_switch - end_time_affordance}")
            end_time_total = time.time()
            logging.info(f"total time per switch: {end_time_total - pose_start_time}")
            a = 2

        return frame_name


def main():
    config = Config()
    take_control_with_function(config, function=_Push_Light_Switch(), body_assist=True)


if __name__ == "__main__":
    main()
