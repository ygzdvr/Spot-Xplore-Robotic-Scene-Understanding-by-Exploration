// Copyright (c) 2023 Boston Dynamics, Inc.  All rights reserved.
//
// Downloading, reproducing, distributing or otherwise using the SDK Software
// is subject to the terms and conditions of the Boston Dynamics Software
// Development Kit License (20191101-BDSDK-SL).

syntax = "proto3";

package bosdyn.api.graph_nav;
option java_outer_classname = "VisualFeaturesProto";

import "bosdyn/api/geometry.proto";
import "bosdyn/api/image.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";

// Generic sparse visual descriptor with a byte blob and a descriptor name.
message GenericDescriptor {
    // Name of the descriptor which identifies how it is to be interpreted.
    string name = 1;
    // Binary blob representing the descriptor.
    bytes data = 2;
}
// Represents a visual descriptor of a feature, usually a sparse visual feature.
message VisualDescriptor {
    oneof visual_descriptor {
        // Oriented Brief (ORB) sparse visual feature.
        bytes orb = 1;
        // Place to put other descriptors not explicitly captured above.
        GenericDescriptor other = 100;
    }
}

// Represents a 2d (pixel-based) detection of a feature in an image.
message VisualKeypoint {
    // The descriptor of the sparse feature, used to match it to other features.
    VisualDescriptor visual_descriptor = 1;
    // Position (pixels) in the image.
    bosdyn.api.Vec2 position = 2;
    // Size of the feature in pixels. If the feature is circular, this is the radius of the circle.
    // If the feature is square, this is the side length of the square.
    float size_pixels = 3;
    // Orientation of the feature in the image plane, radians. Counterclockwise.
    float orientation = 4;
    // The depth (in meters) from the camera if it exists, or empty otherwise.
    google.protobuf.DoubleValue depth_measurement = 5;
    // 2x2 Covariance matrix of the position measurement's uncertainty.
    bosdyn.api.Matrixf position_covariance = 6;
    // Expected variance of the depth measurement, if it exists.
    google.protobuf.DoubleValue depth_variance = 7;
}

// Represents a set of visual features collected  at a particular time from a particular camera
// source. Associates an image geometry + pixel data with visual features extracted there.
message VisualKeyFrame {
    // The visual features extracted at the camera image.
    repeated VisualKeypoint keypoints = 1;
    // Contains the actual data in the image capture (may be compressed), and information
    // about the source. Note that the raw data may be omitted if visual features are already
    // extracted.
    ImageCaptureAndSource image_capture_and_source = 2;
    // Transformation from a bundle frame to the image. Depending on the context,
    // the bundle frame may be the body, odometry, etc.
    bosdyn.api.SE3Pose bundle_tform_image = 3;
}

// Represents a bundle of visual KeyFrames taken around the same time. For example, if the robot has
// many cameras, this represents all of the cameras captured at around the same time/location.
message VisualKeyFrameBundle {
    // A number of key frames, possibly from different sources.
    repeated VisualKeyFrame key_frames = 1;
    // Reference frame that the keyframes' poses are expressed in.
    string bundle_frame_name = 2;
    // Frame tree snapshot mapping common poses at record time (odom, body, etc.) to each other and
    // the bundle frame.
    bosdyn.api.FrameTreeSnapshot frame_tree_snapshot = 3;
}

// A 3D position with a covariance estimate.
message PositionWithCovariance {
    // The vector is to be interpreted as a 3D position in a frame.
    bosdyn.api.Vec3 position = 1;
    // 3x3 covariance matrix representing uncertainty in the position.
    bosdyn.api.Matrixf covariance = 2;
}

// A 3D direction with a covariance estimate.
message DirectionWithCovariance {
    // The vector is to be interpreted as a 3D normalized direction in a frame.
    bosdyn.api.Vec3 direction = 1;
    // 2x2 covariance matrix representing uncertainty in the direction (in a local tangent frame).
    bosdyn.api.Matrixf covariance = 2;
}

// Indexes an observation of a landmark at a particular bundle, keyframe and keypoint.
// Waypoint snapshots have bundles of keyframes, each keyframe has a number of extracted keypoints.
// Observations are structured as:
// bundle_0 ...
// bundle_1
// .... keyframe_0
// .... keyframe_1
// ........ keypoint_0
// ........ keypoint_1
// ........ ...
// ........ keypoint_J
// .... ...
// .... keyframe_K
// ...
// bundle_N
message LandmarkObservationIndex {
    // The bundle from within the waypoint snapshot that this
    // landmark observation came from.
    int32 bundle_id = 1;
    // The keyframe from within the bundle that this observation came from.
    int32 keyframe_id = 2;
    // The keypoint within the keyframe that this observation came from.
    int32 keypoint_id = 3;
    // Time of the camera image which observed this landmark.
    google.protobuf.Timestamp timestamp = 4;
}

// Represents a 3D landmark that has some visual descriptor attached to it.
message VisualLandmark {
    // Unique ID of the landmark. Ids of landmarks are unique only in a particular instance of a
    // graph nav map. Ids of landmarks may change as maps update.
    int64 id = 1;
    // The landmark may either be a full 3D landmark (in which case it is a point), or an
    // orientation-only landmark (in which case it is a normalized direction). The frame of the
    // landmark is left ambiguous here; generally the container of the landmark will specify which
    // frame it is in. Note that landmarks may have *both* position and direction. A 3D position
    // with covariance.
    PositionWithCovariance position_with_covariance = 2;
    // The vector is to be interpreted as a normalized 3D direction in the landmark frame. This
    // represents the direction "into" the landmark from where it was first observed.
    DirectionWithCovariance direction_with_covariance = 3;
    // The canonical descriptor associated with this landmark. If a landmark looks different from
    // different angles, then multiple landmarks are likely to be created for it. This will be set
    // whenever the first observation is made of a landmark to create it.
    VisualDescriptor visual_descriptor = 4;
    // Indices of the observations that support this landmark.
    repeated LandmarkObservationIndex landmark_observations = 5;
}

// A group of 3D landmarks. These landmarks may be associated with a single waypoint, or with groups
// of waypoints.
message VisualLandmarks {
    // Unorganized 3d landmark cloud.
    repeated VisualLandmark landmarks = 1;
    // Name of the reference frame that the landmarks are in.
    string landmark_frame = 2;
    // The frame tree must contain, at minimum, the landmark_frame and some other frame that the
    // waypoint or current robot body knows about (for example, "odom" or "vision").
    FrameTreeSnapshot frame_tree_snapshot = 3;
}
